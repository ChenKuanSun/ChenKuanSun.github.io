[{"title":"使用Amplify持續交付Angular專案到Serverless Web app上","date":"2019-07-30T17:46:43.000Z","date_formatted":{"ll":"Jul 31, 2019","L":"07/31/2019","MM-DD":"07-31"},"updated":"2020-04-13T23:55:01.646Z","content":"前言身為Angular開發工程師，開發過程中總有需要部署到伺服器上測試的時候，因此在開發專案的過程中，可以做到自動化部署到開發環境測試，並進一步到測試、產品週期流程，也是必備技能之一。\n而現在三大雲端商都開始實踐新的概念， Agile、CI、CD、DevOps、Scrum、TDD 等名詞，說實在的，對於筆者接觸前端框架不到半年及沒有進大公司被蹂躪過的新人來說，根本摸不清楚，但筆者就是懶人(減少不必要的SFTP複製貼上，一個一個檢查等閒雜時間)，對於筆者來說，AWS推出的Amplify後端整合及無伺服器框架無異是一個很棒的懶人包(?)\nAmplify 本身支援後端整合的服務分析工具 - AWS Pinpoint\nAPI後端 - API Gateway和Lambda\n直接存取S3 - S3, CloudFront\n數據存儲 - DynamoDB\n身份驗證 - Cognito\n推送通知 - AWS Pinpoint\nGraphQL - AppSync\n這些整合的服務除非有意願把整個專案架構都部署在AWS上(請洽AWS官方架構師)，不然還是建議一步一步根據專案來串接，因為很多服務需要在專案上做優化處理，不然會有高費率的問題。\n這篇文章主要講解最簡易的開始，把現成的Angular專案放到Amplify上，並開始使用自動化部署流程。\n準備專案要持續交付的前提是你的專案必須有版控工具，如Github、Bitbucket、GitLab等常見的Git工具。如果只是單純想用他們的服務架設，就直接上傳就可以了。\n今天創建一個簡單的Angular APP ，就用大家熟知的Hello World!\n其實單純部署流程其實很簡單：\n專案放到Git上\n連接到Amplify\n設定好構建流程\n根據需求設定Domain、Hook後面會分章節詳細介紹後端整合的流程\n1. 專案放到Git上這邊示範用AWS他們家的Codecommit\n建立流程是\n建立儲存庫。\n建立IAM使用者連線帳密(或SSH金鑰)。\n上傳專案。\n我們先到AWS上建立一個儲存庫，到控制台尋找CodeCommit，點選建立儲存庫\n建立好之後會提示你\nText1使用根帳戶登入。您不能對根帳戶設定 SSH 連線，且不建議對根帳戶設定 HTTPS 連線。請考慮以 IAM 使用者身分登入，然後設定您的連線。設定遠端連線一般來說Git常見的有兩種方式，HTTPS及SSH金鑰，而為了簡單起見，我們使用一般常用的HTTPS來做存取。\n到右上角點選安全登入資料來準備建立IAM使用者登入帳密。\n然後點選使用者(如果是用AWS CLI請去 存取金鑰 (存取金鑰 ID 和私密存取金鑰) 設定)\n接下來創立要連到儲存庫的使用者，如果有多人的話就可以多建立幾個，務必勾選程式設計方式存取 ，如果有要讓使用者用Console介面登入的話才勾選下面的 AWS Management Console 存取\n通常建議在工作環境中根據權限建立群組來做統一管理，但因為這邊是本人自己使用的帳號， 選擇最大管理員權限，輸入群組名字。\n完成之後建議點選下載帳密，妥善保存在隔離環境。建立完使用者之後進到使用者裡面進行Codecommit遠端連結的設定。\n根據個人喜好選擇連線方式，我們此範例用簡單的HTTPS，然後把帳號密碼記下來，接下來就是使用我們常用的VSCode工具準備上傳我們的專案。\n先到儲存庫首頁點選複製HTTPS，接下來會自動複製到剪貼簿。\n到VSCode裡設定遠端儲存庫。\n必須要有AWS Credential Helper 才找得到儲存庫唷沒裝的人可以看我上一篇的Serverless文章或直接搜尋我的部落格。裝好AWS CLI之後請輸入以下\n12git config --local credential.helper \"!aws.cmd codecommit credential-helper $@\"git config --local credential.UseHttpPath true已經安裝好的人直接PUSH上去\n12345git initgit add .git commit -m \"first commit\"git remote add origin https://git-codecommit.ap-southeast-1.amazonaws.com/v1/repos/angular-web-appgit push -u origin master接著上傳(帳號密碼就輸入剛剛IAM使用者創立的帳密)\n 完成之後可以看到CodeCommit已經有了專案。\n2. 連接到Amplify建立Amplify流程是\n連接儲存庫。\n設定自動化部署腳本及監看分支類別。\n開始部署。\n到Amplify之後點選我們需要使用的儲存庫，如果是用其他儲存庫的話，確保你有該儲存庫管理員權限。這邊我們就選擇CodeCommit\n設定好之後，選擇我們的儲存庫跟要發行部署的分支。\n接下來選擇APP名稱，接下來是最重要的部署腳本基本上範本是這樣(YAML格式)：\n12345678910111213141516version: 0.1frontend:  phases:    preBuild:      commands:        - npm ci    build:      commands:        - npm run build  artifacts:    baseDirectory: dist/Angular-Web-App    files:      - '**/*'  cache:    paths:      - node_modules/**/*版本就是部署腳本的版本，其中Amplify部署過程中分三大部份:\nenv\nbackend\nfrontend\nenv代表部署過程中的環境變數，backend是配合後端整合的amplify cli來設定Lambda、GraphQL等無伺服器後端服務。另外每部分可以設定run-as，如果有自行上傳的Docker Image的話可以自行設定。而我們單純只是部署前端的話只要保留frontend的部分就行了。\n1234567phases:    preBuild:        commands:        - npm ci    build:        commands:        - npm run build在各部分還分為phases、artifacts、cache，\nphases這部分就是我們常用的構建指令細分preBuild, build, 額外有postBuild, install(自訂Docker可以使用)強烈建議分多部分，因為除錯的時候會比較清楚卡在哪一個方向，盡量不要全塞在build裡。\n1234567run-as: Linux-user-namecommands:    - command    - commandfinally:    - command    - command內含三個基本指令，用什麼身分跑，command指令，跟完成之後的command。都是根據專案需求來設定。\npreBuild其實就是在構建前要做的事情，通常在Angular專案在構建前都會npm i來取得所有package.json內定義的依賴項，而在自動化部署方面，npm提供了npm ci的指令來執行自動化安裝流程，如果有一些私人的第三方套件需要安裝的話可以使用\n123456commands:    - npm config set &lt;key&gt; &lt;value&gt;    - npm config set registry https://registry.npmjs.org    - npm config set always-auth true    - npm config set email hello@amplifyapp.com    - yarn install也可以安裝需要的系統套件\n12commands:    - yum install -y &lt;package&gt;build其實就是我們Angular常見的build指令，如果有個人需求可以設定base-href等不一樣的設定\n1ng build --prod --base-href /我個人都直接npm build懶人包，或是在package.json裡設定好json裡設定好prodToAmplify的腳本在裡面直接跑npm run prodToAmplify。\npostBuild就是跑完之後要做的事情。因為這專案沒有什麼需要跑完之後要做的事，有些人可能會想要跑完之後把S3的資源Copy到這邊的dist資料夾裡，就自行設定為主。\n12- echo Entered the post_build phase...- echo Build completed on `date`以上是Build過程盡量在前後加上echo讓log檔更漂亮\nartifactsbuild結束之後要設定搬移到部署伺服器上的東西通常baseDirectory會對應到angular.json裡的”outputPath”，表示這邊的資料夾內容都是要部署到伺服器的檔案，而有可能有些資料沒有要公開的可以在files中而外排除該資料夾。預設都是*/來把內容所有的資料部署上去。\ncache12cache:    paths: node_modules/**/*代表部署過程中的快取資料，放在這邊的東西會被快取到S3上做存放，通常會把node_modules放進來，之後構建速度會快很多，少了下載這步。\n下面有進階設定可以選擇自己上傳的Docker image跟設定環境變數，我們這次保留直接部署。\n完成之後可以看到開始構建，左邊有面板可以設定自己的Domain、Email notification、Rewrites and redirects。Angular如果不是在根目錄下需要重新導向的話如–base-href為/hello/就要在Rewrites and redirects裡設定redirects到/hello/index.html\n完成之後左邊會有預覽圖，流程圖的按鈕可以點進去檢查輸出日誌，如果有錯誤也會顯示。\n點了預覽圖下面的網址就會直接到網站上瀏覽，也有內建SSL\n點選Verify的話可以看到不同裝置上呈現的效果上面也有構建中的詳細資料，可以知道我們構建了3分鐘，接下來只要提交到master就會直接自動構建，\n當然要分開環境的話可以點選右上角的ConnectBranch來連結開發分支跟測試分支，一次開三個不同部署的網站來做工作流程。\n今天初步講解直接將現有專案搬上自動化流程，但這只是無伺服器後端服務的開始，後面幾個章節會來講解用Angular-amplify的整合後端來作完整的無伺服器網站APP。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"cover.png","plink":"https://chenkuansun.github.io/2019/07/31/amplify/"},{"title":"AWS Serverless 實作 — 下","date":"2019-07-25T17:30:25.000Z","date_formatted":{"ll":"Jul 26, 2019","L":"07/26/2019","MM-DD":"07-26"},"updated":"2020-04-13T23:55:01.573Z","content":"AWS Serverless 實作 — 下延續上篇AWS Serverless 實作 — 上篇章，有幸參加了AWS在北科集思會議中心開的Workshop課程，由講師手把手帶領實作，並部署到線上來串接服務。\n\n使用OAuth 2.0啟用第三方應用程序\n我們先用先前的方式創建一個Lambda函式ListUnicornRides，並在Repo裡面把ListUnicornRides.js複製到編輯器，並記得把政策角色改成我們在前面設定好的角色。\n\n接下來創立另一個函式ListUnicornAuthorizer，完成之後再編輯器的位置點選上傳Zip檔\n\n上傳成功之後會在編輯器中出現程式碼\n\n完成之後編輯下面的環境變數，屬性填入USER_POOL_ID，值就是Config.js我們填過的userPoolId，\n\n到API Gateway的授權方部分，點選創建新的授權方，選擇Lambda驗證而不是Cognito，選擇ListUnicornAuthorizer函式當我們的驗證器，設定如下\n\n創建完成之後我們在資源裡的/ride增加一個GET Methods，\n\n按照我們的作法，完成之後一樣在方法請求裡面選擇驗證，\n\n選擇我們剛剛成功上傳的自定義驗證。完成之後請點選部署API\n到S3點選創建儲存貯體\n\n輸入唯一的儲存貯體名稱直接點選建立，\n{\n     &quot;Version&quot;: &quot;2012-10-17&quot;,\n     &quot;Statement&quot;: [\n         {\n             &quot;Effect&quot;: &quot;Allow&quot;,\n             &quot;Principal&quot;: &quot;*&quot;,\n             &quot;Action&quot;: &quot;s3:GetObject&quot;,\n             &quot;Resource&quot;: &quot;arn:aws:s3:::[YOUR_BUCKET_NAME]/*&quot;       \n         }     \n     ] \n}把上面的Name改成你的儲存貯體名稱之後進到儲存貯體更改設定，我們先把公開存取打開（不然會出錯），\n\n\n接下來到政策這裡填入剛剛的程式碼。之後到屬性打開靜態網站託管。\n\n完成之後我們要來設定CDN\n\n建立分佈\n\n因為我們是做靜態網頁，所以點選Web。\n\n並確保重新導向Http到Https加強安全性，在底下的分佈請選擇最低價格等級的CDN\n\n不然會分佈到全球CDN。\n接下來到Cognito設定我們要來取用的App Client，到先前設定的WildRydes，再到左邊的應用程式用戶端裡增加可以連線的Client端，\n\n一樣取消勾選用戶端密碼並建立。\n\n點選左邊的網域給驗證的服務加入網域，可以根據自己需求自訂。\n加入完成之後我們需要建立起資源伺服器。\n\n點選左邊資源伺服器，開啟之後新增以上參數\nUnicornServer\nUnicornManager \n&quot;Allow listing of rides for unicorns&quot;描述可以自己定，完成之後建立，接下來設定Client端的需求，點選，左邊的應用程式用戶端設定。\n\n根據上面設定或是自己的需求。請記得選對卡片，不要選到第一個，點選儲存。\n接下來上傳Oauth測試頁面，我們把AWS WorkShop Repo的資料夾下載下來，更改Config.js，\n\n根據上面的講解把我們剛剛設定的東西填入，接下來到資料夾底下，打開Terminal\naws s3 sync . s3://YOUR_BUCKET_NAME --region YOUR_BUCKET_REGION使用上述程式碼把資料夾傳上去，並注意更改region name，接下來就會把整個資料夾上傳到S3，\n上傳完成之後，我們可以在網址輸入cloudfront提供的CDN網址，來看我們的網頁狀況。\n\n\n還可以重設密碼等等\n\n登入之後就可以看到登入畫面了。\nServerless GraphQL API：\n既然是Serverless，當然不可缺少GraphQL API，這邊將使用AWS AppSync來實作GraphQL API後端。\n\n首先到AppSync Console創建新的app，選擇Import，然後點開始。\n\n選擇之前創建的資料表，創建。\n\n接下來新開一個TAB到DynamoDB，選擇資料表，點選項目，隨意點一個Row，並打開它，\n\n點選顯示格式到 Text，並勾選DynamoDB JSON，觀察欄位的Type，並一一填入剛剛的創建設定。\n\n基本上依據範本做的話就是上述設定，\n\n到下一頁輸入API名稱，點選創立\n\n成功之後會出現上述畫面。\n建立一個Query查詢UnicornName:點選左邊的Schema，然後在Schema中尋找type Query{}，並加入以下程式碼：\ngetRidesByUnicornName(UnicornName: String, limit: Int, nextToken: String): RidesConnection\n按下儲存之後，在Resolvers可以看到更新\n\n點下Attach來啟用Query，\n\n資料表選擇Rides，在配置的部分選擇分頁搜尋。\n\n把Query改成Scan，屬性改成UnicornName\n{\n    &quot;version&quot; : &quot;2017-02-28&quot;,\n    &quot;operation&quot; : &quot;Scan&quot;,\n    &quot;filter&quot; : {\n        ## Provide a query expression. **\n        &quot;expression&quot;: &quot;UnicornName = :UnicornName&quot;,\n        &quot;expressionValues&quot; : {\n            &quot;:UnicornName&quot; : {\n                &quot;S&quot; : &quot;${ctx.args.UnicornName}&quot;\n            }\n        }\n    },\n    ## Add &apos;limit&apos; and &apos;nextToken&apos; arguments to this field in your schema to implement pagination. **\n    &quot;limit&quot;: $util.defaultIfNull(${ctx.args.limit}, 20),\n    &quot;nextToken&quot;: $util.toJson($util.defaultIfNullOrBlank($ctx.args.nextToken, null))\n}可以複製貼上，\n\n下一個卡的配置選擇Return paginated results，接下來儲存。\n設定權限：儲存之後點選左邊的Setting並設定權限\n\n選擇由User Pool來處理權限，並選取前篇文章設定，接下來儲存。\n我們需要驗證剛剛的查詢是否正常，假設有在先前的實作中，有實際註冊一個第三方Oauth帳戶，那我們就可以利用那個帳戶，來做驗證流程。點選左邊的Queries，點選Login with User Pools並輸入先前在Cognito\n\n接下來點選Login with User Pools，然後把測試用的用戶帳密輸入，務必注意＠的部分要改成-at-，\n\n接下來按下儲存，我們就開始測試Query流程\n\n在開始之前先把創建的語法刪掉，如上圖，不然會創建資料。\n\n之後就可以在這邊測試各個查詢，\n\n接下來我們加入剛剛建立的查詢語法，因為我在資料表的部分有輸入錯誤，所以才填ID，照著範例走的話是填入Id ，點擊查詢（箭頭）按鈕，\n\n加入之後就可以測試看右邊的結果，這就是利用AWS AppSync的GraphQL API測試。\n清理實作的資源：AppSync GraphQL API\n\n到AppSync 控制台。\n\n選好這次創的API。\n\n從右上角選擇“ 刪除 ”。\n\n完成。\n\nOAuth清理\n到CloudFront 。\n\n選擇在範例創建好的Web項目，然後先停用，如果選最高的服務，應該會需要一段時間。\n\n刪除該項目。\n\n到S3控制台，直接把unicornmanager-xxx刪除。\n\n到Lambda控制台，把ListUnicornRides，ListUnicornAuthorizer函數刪掉。\n\nREST API\n到API Gateway。\n\n把前面創的API Gateway刪掉（進到API裡面有個操作可以按刪除）。\n\nServerless Backend\n到Lambda。\n\n把RequestUnicorn函數刪掉。\n\n點右上角頭像的安全登入資料。\n\n到角色，搜尋WildRydesLambda 把剛剛的角色刪除。\n\n到DynamoDB。\n\n選資料表，然後刪除資料表，記得一並刪除CloudWatch。\n\nUser Pool\n到Amazon Cognito。\n\n選擇 WildRydes，先到左邊的網域名稱刪除掉網域。\n\n回到首頁，右上角會有刪除集區，刪除。\n\nWeb App\n到Amplify。\n\n刪掉APP(進App之後右上角）\n\n到AWS CodeCommit。\n\n刪掉Repo。\n\nCloudWatch\n\n到 CloudWatch 。\n\n選擇日誌，刪掉這次實作的所有日誌。\n\n完成結語關於圖片預處理的部分會另外開章節講解，這兩篇章節主要還是大略講解了各服務的詳細設定。這次WorkShop主要還是很豐富的講解了AWS各項服務的內容，主要還是推薦想要設計架構的人來學習，因為在服務間的串接，經過這次的WorkShop也比較清楚如何在設定上清楚的設定權限跟服務，還可以處理好自動化流程，減去工程師在非業務邏輯上的時間，當然也推薦全端工程師修煉好雲的架構流程，因為在服務串接上，可以根據自己需求串接不同雲，但會比較建議全都在同一個雲上，相對的串接上比較單純容易，服務相容性也會高很多。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2000/1*mRv_YtyDuE_wypl2mGvbew.png","plink":"https://chenkuansun.github.io/2019/07/26/AWS_Serverless_04/"},{"title":"AWS Lambda 除錯小技巧-Python","date":"2019-07-25T17:30:25.000Z","date_formatted":{"ll":"Jul 26, 2019","L":"07/26/2019","MM-DD":"07-26"},"updated":"2020-04-13T23:55:01.574Z","content":"常常在Lambda莫名其妙502，找Log開Test除錯又超級麻煩嗎?可以試試用Python的Class-based Decorator及Try Except結合，直接把Traceback傳回來。\nLet’s Start Coding可以包一個Library到Layer裡面，定義一個Class-based Decorator，\n1234567891011121314151617181920212223import tracebackclass developer_mode(object):  def __init__(self, status=False):    self.status = status  def __call__(self, func):    def wrapper(*args, **kwargs):      if self.status:        try:          response = func(*args, **kwargs)        except Exception:          response = &#123;            # (option) Define your statusCode like 5xx \\            # link to API Gate Way            \"statusCode\": 200,            # (option) Define your body as you need            \"body\": json.dumps(traceback.format_exc().split('\\n')),          &#125;        finally:          return response      else:        return func(*args, **kwargs)    return wrapper之後在Lambda前面加就可以做Debug\n12345#Set True to enabling Developer_mode  #leave as default like developer_mode() or developer_mode(False) #to disable developer mode@developer_mode(True)def lambda_handler(event, context):後續如果有更多的小技巧就會繼續分享。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://miro.medium.com/max/700/0*YGwj6hSUumVQZqPb.png","plink":"https://chenkuansun.github.io/2019/07/26/AWS_Serverless_05/"},{"title":"AWS Serverless 實作 — 上","date":"2019-07-23T18:46:25.000Z","date_formatted":{"ll":"Jul 24, 2019","L":"07/24/2019","MM-DD":"07-24"},"updated":"2020-04-13T23:55:01.573Z","content":"AWS Serverless 實作 — 上延續上幾篇Lambda的篇章，有幸參加了AWS在北科集思會議中心開的Workshop課程，由講師手把手帶領實作，並部署到線上來串接服務。\n\n安裝假設大家都有遵循上幾篇教學在本地端安裝好SAM(Serverless Application Model)，並成功啟用AWS-CLI及憑證，Connect完成後請先輸入\naws sts get-caller-identity可以看見你已經連線的AWS帳號、ID及ARN，\n{\n    &quot;UserId&quot;: &quot;XXXXXXXXX&quot;,\n    &quot;Account&quot;: &quot;XXXXXXXXX&quot;,\n    &quot;Arn&quot;: &quot;arn:aws:iam::000000000000000:user/000&quot;\n}使用AWS Amplify Console創建靜態頁面我們先試做AWS Amplify Console，這個是AWS 針對Angular、React、Vue等常用框架做一個Git工作流程自動化部署的控制台，首先我們會用到以下服務：\nAWS Amplify Console\n\nAWS CodeCommit\n\n有興趣的讀者可以去看相關介紹，基本上CodeCommit這個服務不是必要的服務，可以使用Github、Bitbucket、Gitlab或是自己處理S3等儲存媒介的儲存庫。要用到codecommit的讀者請先在本地Git bash設定裡加入設定，這個設定是讓git使用IAM憑證登入AWS codecommit\ngit config --global credential.helper &apos;!aws codecommit credential-helper $@&apos;\ngit config --global credential.UseHttpPath true完成之後我們需要在AWS Codecommit創建一個Repo，創建完後點選右上角的複製Https Clone到本地端\n\n從S3下載範例並存放到剛剛的repo資料夾\naws s3 cp s3://wildrydes-us-east-1/WebApplication/1_StaticWebHosting/website ./ --recursive\n\n複製好之後push上去Repo，並到Amplify Console console page開始自動化佈屬流程，點選Deploy下面的Start，如果是控制台頁面點選Connect，\n\n點選完之後，保持預設設定（當然有特殊需求可以根據自己情況修改），\n\n接下來會開始部署流程，可以點入Provision觀察Log\n\n可以知道他們是直接拉Docker來創建流程，如果一直部署有問題可以考慮拉他們的Image自己本地測試，\n\n接下來Build流程會開始Clone流程，會從Repo Clone到容器內開始Build\n\n\n完成之後可以點選網址，就可以看到部署玩的網頁內容，可以點選Verify，會自動幫忙Scale各個手機版面的View。\n\n之後只要改變Repo然後Push的話，Amplify Console會自動幫你進行到佈建流程，\n\n所以建議大家不要用Master來當作開發的分支，盡量在Code Review完之後再Merge進來做Deploy的動作。\n使用Cognito用戶身份驗證首先建立身份集區\n\n點選管理使用者集區，然後點選建立使用者集區，\n\n填入唯一名稱，然後點選預設值，直接按建立，可以根據自己需求更改，\n\n建立完成之後點選左邊一般設定的應用程式用戶端來建立WebApp連線使用的設定檔，\n\n取消產生用戶端密碼讓使用者自行輸入，填用戶端名稱（userPoolId），\n建立完成會有一組連線的key，把他複製出來，到上一段的Repo裡面的js/config.js，打開之後填入剛剛的資訊\n\n並且在這裡填入PoolId（ 在使用者集區上面），然後儲存之後Push上去\n\n等到部署完成之後，可以到網址下的/register.html裡註冊帳號，完成之後如果點選沒反應，代表有問題，記得打開瀏覽器的DevTool檢查Error。填完之後會寄一封認證信到信箱並到認證頁面。\n\n然後驗證完之後就可以實施登入動作了。\n在OSX這邊使用者可能會遇到Push上去有403的問題，問題原因在於Mac會將金鑰存入鑰匙圈，然後15分鐘後AWS那邊會刷新，就會有403的狀況，有幾個方法\n修改codecommit驗證金鑰成顯性金鑰\n\n改用SSH Push\n\n直接在Mac裡搜尋Keychain，在Keychain內搜尋AWS Region(us-eastXXX)，會看到Git-codecommit開頭的金鑰，進入之後到取用控制，把應用程式刪除，就可以使用，每次都會詢問，都要按拒絕，比較煩人的是每次Fetch都會問，最好的方式是用上面兩種方法。\n\n\nServerless後端架構在開始之前如果沒有預先設定IAM的話，要先設定好 IAM角色來使用AWS服務串接，並給Lambda函數權限將日誌寫入Amazon CloudWatch Logs並讀寫DynamoDB。\n我們先開好DynamoDB的Table，\n\n到首頁點選建立資料表。\n\n輸入好資料名稱，然後索引設定，創立資料表。\n設定IAM，先到帳號點選安全登入資料。\n\n進入控制台之後，點選左邊角色，並建立角色，點選Lambda服務\n\n點選下一步，在輸入欄裡搜尋\nAWSLambdaBasicExecutionRole\n勾選之後輸入IAM的名稱等，點選下一步創立，可以加入自己的Tag，一直到建立完成。\n\n接下來輸入剛剛的關鍵字可以看到創立完成，點進去角色，之後可以看到詳細資料\n\n點選右邊的新增內嵌政策來允許Lambda存取其他服務。\n\n填入DB會過濾出服務，點選DynamoDB\n\n打入Put過濾出Put點選PutItem\n\n輸入剛剛建立的Dynamodb建立的資料表資訊，也可以到DB裡面直接複製ARN，然後輸入政策的名稱。建立好政策。\n建立Lambda的函式：\n\n點選建立函式，在Name的部分輸入：\nRequestUnicorn並選擇Node.js的環境（範例專案是使用這個版本）\n\n在下面的許可中點開，並選擇我們剛剛創立的角色。\n\n點選建立函式，\n\n滑鼠拖到下面可以看到編輯區把Repo裡的requestUnicorn.js內容整段複製取代掉編輯區裡的程式碼，因為主索引鍵是RideId，所以要確認好nodejs裡的範例程式碼的資料有沒有對齊主索引鍵（大小寫視為不同）。按下儲存之後，在右上的選擇測試事件內點選設定測試事件。\n\n在編輯區填入這段測試的Request\n{\n     &quot;path&quot;: &quot;/Rides&quot;,\n     &quot;httpMethod&quot;: &quot;POST&quot;,\n     &quot;headers&quot;: {\n         &quot;Accept&quot;: &quot;*/*&quot;,\n         &quot;Authorization&quot;: &quot;eyJraWQiOiJLTzRVMWZs&quot;,\n         &quot;content-type&quot;: &quot;application/json; charset=UTF-8&quot;\n     },\n     &quot;queryStringParameters&quot;: null,\n\n     &quot;pathParameters&quot;: null,\n     &quot;requestContext&quot;: {\n         &quot;authorizer&quot;: {\n             &quot;claims&quot;: {\n                 &quot;cognito:username&quot;: &quot;the_username&quot;\n             }\n         }\n     },\n     &quot;body&quot;: &quot;{\\&quot;PickupLocation\\&quot;:{\\&quot;Latitude\\&quot;:47.6174755835663,\\&quot;Longitude\\&quot;:-122.28837066650185}}&quot; }記得在Path裡面把ride改成資料表的名稱。\n點選測試可以看到\n\n這樣就完成了Lambda的實作\n使用Amazon API Gateway的RESTful API呼叫Lambda\n首先到 Amazon API Gateway Console創立API\n\n創立之後我們要先串接JWT驗證，點選左邊的授權方並建立。\n\n輸入名稱，Cognito選擇早些時候創立的使用者集區，建立好之後到我們部署好的頁面，在剛剛登入成功的時候有返回一組Token，\n\n複製下來之後，到API Gateway來貼上測試\n\n貼上測試完之後會返回200代表成功。\n\n接下來要練習創立資源，到資源裡面點選建立資源，\n\n勾選CORS之後建立，點擊ride來建立endpoint的Methods\n\n然後選擇POST\n\n創立好之後我們要連結到Lambda來讓Endpoint來執行這個Function，勾選代理整合，然後輸入Lambda的名稱。\n\n完成之後會創立Post，裡面有POST的各個流程Node，因為要建立權限不讓其他人隨意存取，所以點選方法請求，把授權方指向使用者集區\n\n點選之後記得點選勾勾來套用，\n接下來部署API\n\n點選操作，然後部署，選擇階段或是新增階段，填入名稱（prod)，按下部署。\n\n接下來到我們Repo裡的config.js裡面把invokeUrl填入上面呼叫用URL在Push上去，等待Deploy完成進去我們的頁面。\n\n點選一個點然後點選上面的按鈕來測試我們的Lambda\n\n接下來就會看到我們的彩虹小馬出現了！也完成了我們的Serverless服務串接。\n下篇，AWS Serverless 實作 — 下如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2000/1*mRv_YtyDuE_wypl2mGvbew.png","plink":"https://chenkuansun.github.io/2019/07/24/AWS_Serverless_03/"},{"title":"使用Visual Studio Code將函數部署到AWS Lambda","date":"2019-07-18T18:46:25.000Z","date_formatted":{"ll":"Jul 19, 2019","L":"07/19/2019","MM-DD":"07-19"},"updated":"2020-04-13T23:55:01.572Z","content":"這篇文章延續使用PyCharm將函數部署到AWS Lambda，因為自己有使用Angular，有需要利用Visual Studio Code環境需求，而剛好在7月15日時AWS推出了VSCode擴充套件，因此特地學習之後來撰寫相關教學。\n環境設定：首先文章會分幾個部分，事前的環境準備需要：\nDocker\n\nPython3\n\nVisual Studio Code\n\n如果不知道電腦本地裡安裝的Python版本的話可以考慮在Command裡輸入下列指令查看版本：\npython -V接下來打開VSCode， 點選擴充套件，搜尋AWS：\nAWS Tookit\n點選安裝，如果有像筆者一樣有同時用VSCode開發很多種語言的話，記得先將不會用到的套件都關一遍，獨立給Python一個工作區。\n因為要遠端存取AWS資源，我們必須先設定好API金鑰，到AWS上打開Console面板\n\n點選安全登入資料\nconsole\n然後打開存取金鑰，獲得一組ID跟KEY\n# aws_access_key_id = [accessKey1]\n# aws_secret_access_key = [secretKey1]然後在VSCode點選Ctrl+Shift+P(OSX請用Command+Shift+P)開啟進階命令列，輸入AWS\n\n會發現AWS Tookit已經包含各種設定，我們點選Create Credentials Profile來輸入剛剛的金鑰，由於筆者已經用Pycharm及SAM Cli創建過金鑰檔案，所以會直接開啟舊檔，一般來說會直接提示使用者輸入檔案名稱，然後輸入Key。\nConfig\n驗證剛剛的金鑰是否能正確登入AWS，開啟進階命令列，輸入AWS\nConnect to AWS\n點選Connect to AWS，會提示問你要用哪個設定檔登入，成功登入之後到AWS擴充套件的面板，可以看見需要新增到面板操作的地區選項。\nRegion\n由於筆者之前測試在個人帳號都是使用新加坡伺服器（台灣朋友可以使用最新的香港伺服器唷），所以選擇新加坡地區。\n\n這時候就會看見已經部署過的專案內容，也可以加入其他地區，在進階命令列打上AWS選擇Show region in the exploer，\n\n當然也可以用AWS面板上的快捷鍵來點選，\n\n就可以看到各個區域部署的服務。\n創建Serverless範例專案要創建一連串範例專案前，必須先設定好本地開發環境，首先需要Python環境，筆者本身是用Anaconda，所以直接用Anaconda環境安裝一個自動化部署及設定SAM（ Serverless Application Model）所有指令的*AWS SAM CLI*安裝AWS-SAM-CLI（務必弄清楚pip安裝後會是在預設的python環境下）：\npip install --user aws-sam-cli\n點選創建新的SAM程序 ，接下來會提示你使用哪種語言設定，\n\n這邊選擇你的Lambda預設語言，後續會詢問是否在當前或是其他資料夾創建專案，選擇好之後輸入名稱，等待佈建完成。\n\n接下來要創建專案的環境，使用Terminal在專案根目錄下打\npython -m venv ./.venv.\n由於筆者的系統有Python2 3，所以會加上python3，然後系統會提示是否套用到本工作區，建議是點選Yes以免後續設定困擾\n\n當然真的沒點到就點選左下角更換環境到剛剛創建的環境。接下來點選App的檔案，如Python就是App.py，\n\n然後可以看到SAM已經幫我們創建好一個Hello World的範例專案了，要在本地建立測試環境，可以點選CodeLens的按鈕，這是VSCode的功能，可以快速建立程式。\n\n先點選Configure來幫我們紀錄資訊，點選之後會創建設定檔，可以根據自己狀況更改。點選Run Locally來開始本地測試。\n\n接下來就會在本地建立一個Docker伺服器並且開啟測試，可以看到我們的測試成功返回了\n{&quot;statusCode&quot;:200,&quot;body&quot;:&quot;{\\&quot;message\\&quot;: \\&quot;hello world\\&quot;}&quot;}有些人使用Python可能會遇到下面這個問題：\nPythonPipBuilder:None - Binary validation failed!問題原因在於，你在執行專案的環境跟選擇專案語言版本是不同的，一開始筆者選擇3.6版本，但遺忘了自己系統是3.7版本，導致出錯，這時候將創立venv環境的python版本調整成跟目標專案語言版本一樣就能解決了。如果要Debug程式的話，可以下斷點，點選Debug Locally就可以進入除錯模式。\n部署我們要進入部署階段，目前都是用預設部署，部署之前請先到S3，在區域伺服器中創建一個Bucket供部署使用。\n\n點選AWS裡的Deploy或是到進階命令列裡輸入AWS點選就可以開始部署過程，會先提示選擇部署描述文件（template.yaml），然後輸入剛剛在S3創建的Bucket名稱：\n\n\n完成之後會開始部署，部署會根據CloudFormation的腳本去部署，如果沒有就會以範本創建新的（S3沒有並不會創建，應該是Toolkit的Bug，因為Pycharm版本會自動創建），這邊等到所有服務完成之後，我們到AWS檢查各服務部署狀況，\n\n可以發現剛剛部署上去的Function已經在Lambda，記得選對區域，不然會看不到自己的Function。Lambda部署的時候已經幫我們選擇好API Gateway，跟前面的範本輸入選擇有關。\n\n\n可以在線上編輯器看到剛剛部署的檔案內容。\n\n可以根據需求設定測試樣板，如果是設定POST，PUT的話可以根據函數內容做變化。\n\n接下來在API Gateway可以看到部署好的Stack。\n\n進到裡面可以看到剛剛部署的API Gateway Proxy，請求指向Lambda。可以點選測試。\n\n點選測試，會看到右邊的回應內文跟日誌，如果跟預期的內容一樣的話就代表成功，但不一定是真實回應內容 ，這是端對端測試的實務經驗，不多做詳解。\n結語：現在無伺服器架構越來越火紅，只要專注於業務邏輯，在雲端中自動部署，就可以免去大多數部署環境的時間，而AWS在Serverless這塊也是很早就戰略部署，隨著VSCode越來越強大（還可以直接遠端開發），雖然較晚進入擴充套件市場，但易用性及方便性極高，相信大家很快就會上手，\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2532/1*UVYAT7_mtodK07lhNti30Q.png","plink":"https://chenkuansun.github.io/2019/07/19/AWS_Serverless_02/"},{"title":"Unity Obstacle Tower 第一章：介紹","date":"2019-06-22T18:46:25.000Z","date_formatted":{"ll":"Jun 23, 2019","L":"06/23/2019","MM-DD":"06-23"},"updated":"2020-04-13T23:55:01.631Z","content":"Unity今年初推出了一個名為「Obstacle Tower」的遊戲，意圖在讓AI在3D環境中解謎跟逃脫的遊戲。這邊假設大家都對RL有基本的認識，今天帶大家如何切入實戰。\n介紹有接觸過RL的人應該對蒙特祖瑪的復仇這塊不陌生，他是一個解謎遊戲，不只是短期獎勵，還要有長期的策略，但到今天的增強式學習相信大家都有發現一個問題，就是都以2D環境為主，而3D空間只有訓練假人站立等等行為，嚴格來說，假人實際給Agent訓練的State也只是一堆參數而已。今天Unity團隊聯手GCP團隊一起創辦了一個國際挑戰賽，製作出了3D版的蒙特祖瑪的復仇，表面上是挑戰賽，實際上是刺激參賽團隊能夠寫出一個可以處理3D影像的增強式學習模型，所以也有OpenAI的參賽者加入。而作者本身有幸進入決賽，由於最近在設計分層強化學習模型有點卡關，所以藉由寫教學文章順便對基礎重新複習，希望可以在這段期間寫出很優秀的模型。也帶大家正式進入真實RL在玩的領域。\n下載並分析環境1：這邊請先根據您的環境下載環境執行檔案。\nLinux (x86_64)\nMac OS X\nWindows\n2：解壓縮後打開執行文件\n這邊會開啟遊戲，這邊講解動作空間（Action space)，\n上下左右各是WASD，左右旋轉鏡頭為KL，跳耀為空白鍵\n右上角的Floor是第幾層，Time是剩餘時間，Tower是隨機種子。\n到下一關（下一層）要進入向上箭頭標記的門。\n這裡每一關都是隨機生成的，有100個隨機種子，另外還有不同主題，所以有非常多的樣本。\n可以實際玩一輪看看，人類平均水平在16層，\n這個是綠色的門，只是通道，從第二層開始就要到第二個房間才能上樓\n時間寶珠是用來增加剩餘時間的。\n在第五層開始有鑰匙，有時候鑰匙會在跳台上面。（這對ＡＩ來說是很困難的動作）\n然後第七層左右就會有黑洞，\n第十層就有推箱子，第十層開始會有不同主題，\n要把箱子推到藍色方格上才會開門，如果不小心推到邊邊，踩紅色的方格就會重置方塊。\n然後第11層開始房間會變大一倍，地上還會有這種旁邊有坑的，掉進去就會直接重來。\n後面還有很多莫名其妙的東西，大家可以自己摸索一下，但相信大家也發現困難度在哪了。\n玩的過程要思考如何讓Agent可以順著路走，不會自殺等等，\n執行檔直接給Agent訓練可以讀的的State目前就是168X168X3(可以調成84X84X3的復古模式)的影像，剩餘時間，箱子數，鑰匙數，跟預設獎勵值\n這些就是我們所謂的觀察空間(Observation spaces)，另外獎勵值就是過一個關卡會給你一分，過一個綠門會給0.1等等。\n但我上一句有說，這是預設獎勵值，實際上增強式學習的獎勵函數，都是自己打造，\n而要先瞭解怎麼設計RL就要先了解環境，架構，\n進而找出；\n觀察空間\n動作空間\n潛在的問題然後總結這些因素來設計\n輸入的預處理(Feature Engineering)\n輸出的動作組合（Action Table)\n獎勵函數（Reward Function)而回饋修正的就是預期的Agent行為跟實際的行為，\n根據不斷人眼觀察實際跟預期的差異，\n去分析是State預處理完的資訊不足還是獎勵函數的設計謬誤，\n這邊我都戲稱為RL心理學，因為很像在調教Agent~\n待續，下一章會講解觀察空間跟動作空間。這段期間大家先玩看看～\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","plink":"https://chenkuansun.github.io/2019/06/23/RL_02/"},{"title":"使用PyCharm將函數部署到AWS Lambda","date":"2019-06-20T18:46:25.000Z","date_formatted":{"ll":"Jun 21, 2019","L":"06/21/2019","MM-DD":"06-21"},"updated":"2020-04-13T23:55:01.572Z","content":"自從Amazon在2014年率先揭開Serverless運算架構的新革命後，無伺服器架構越來越火紅，但是台灣卻很少有人討論相關技術，我試用了Cloud Function(GCP)，也在專案上導入了AWS Lambda，也吸收了不少經驗，因此也來寫一些系列文章來講解各大無伺服器架構的開發體驗過程。\n環境設定：首先文章會分幾個部分，事前的環境準備需要：\nDocker\n\nPython3\n\nPycharm\n\n如果不知道電腦本地裡安裝的Python版本的話可以考慮在Command裡輸入下列指令查看版本：\npython -V接下來安裝AWS-SAM-CLI（務必弄清楚pip安裝後會是在預設的python環境下）：\npip install --user aws-sam-cli\n接下來打開Pycharm， 點選Configure&gt;Preferences，到Plugins，點選Marketplace，在搜尋欄打入AWS：\n\n點選AWS Tookit安裝，安裝完成後，點選OK，接下來創建新的專案：\n\n會看到AWS Serverless Application的選項，這時候點選創建新環境，然後Base指向剛剛AWS-SAM-CLI安裝的Python環境之中，Template點選Hello World範本。\n\n接下來創建完成後，打開專案，點選app.py，就會看到基本的Hello World範本，我們需要做一點AWS環境設定，點選右下角的AWS Credential。\n\n先點選要開啟Serverless環境的區域，這邊筆者選擇SG，大家可以試試最近AWS新部署的HongKong區域，點選完之後還要輸入AWS ACCESS KEY才可以遠端部署到AWS伺服器上，先到AWS上打開Console面板\n\n點選安全登入資料\n\n然後打開存取金曜，獲得一組ID跟KEY\n# aws_access_key_id = [accessKey1]\n# aws_secret_access_key = [secretKey1]到剛剛Pycharm右下角點選Edit AWS Credential files編輯認證檔案，下面有一組profile user1，取消Comment之後把ID跟KEY貼上去，如果有多組就可以自定義名稱相同方式寫入。\n運行本地測試環境：\n回到剛剛的檔案，會發現在Function前面有個Lambda符號，點選他的話，就會出現Run的選項，第一次點選Run會提示你選擇運行選項：\n\n確認好運行環境是預設想要的Python版本，Handler指向你的Function(飯粒是app.lambda_handler)\n\nInput的部分選擇會用到Lambda的服務，我們這邊選擇API Gateway代理服務，選擇好之後點選Run\n\n第一次運行的話會下載AWS Lambda Docker Image在本機建立容器，會需要一段時間，通常Image後面會很多……………….，完成建立容易之後開始執行就會出我們範例程式碼的HelloWorld，由於這個Lambda概念是Serverless，所以範例程式就是大家熟知的Response Status Code 200的回應。\n部署：\n在Project點選右鍵，在選單最下面會有Deploy Serverless Application的選項，一樣點選之後，\n\n由於Lambda遠端部署是將檔案等等放到S3上，再委託由CloudFormation部署到Lambda中，如果沒有既定的服務就直接創建新的，開始部署之後，\n\n會看到打包上傳的過程，有些人可能會遇到找不到[‘aws’]指令的問題，是因為在打包過程中找不到SAM AWS指令，必須在Base環境中正確安裝AWS-SAM-CLI才可以繼續運行，\n\n上傳成功之後，會打開CloudFormation的工作視窗，這邊會監控所有服務的部署狀況，如果有寫好的部署腳本的話，就會根據部署腳本顯示各任務狀況，這邊等到所有服務完成之後，我們到AWS檢查各服務部署狀況，\n\n可以發現剛剛部署上去的Function已經在Lambda，記得選對區域，不然會看不到自己的Function。\n\nLambda部署的時候已經幫我們選擇好API Gateway，跟前面的範本輸入選擇有關。\n\n可以在線上編輯器看到剛剛部署的檔案內容。\n\n可以根據需求設定測試樣板，如果是設定POST，PUT的話可以根據函數內容做變化。\n\n接下來在API Gateway可以看到部署好的Stack。\n\n進到裡面可以看到剛剛部署的API Gateway Proxy，請求指向Lambda。可以點選測試。\n\n點選測試，會看到右邊的回應內文跟日誌，如果跟預期的內容一樣的話就代表成功，但不一定是真實回應內容，從筆者實際經驗可以發現，從API Gateway做CORS出來的時候，必須也要在Lambda的Header裡同步加入。\n結語：現在無伺服器架構越來越火紅，以前的後端工程師可能都需要維護伺服器等等人家說MIS要做的事情，現在部署到雲端，又有Serverless架構，基本上實體的伺服器已經慢慢的被淘汰。除了機敏資料備份以外，無伺服器架構在開發過程中大大減少了全端工程師在整備環境的時間跟精力，只要專注於業務邏輯，在雲端中自動部署，整合好SQL，Lambda function，API Gateway，就可以免去大多數部署環境的時間，加上內部安全性基本都由雲端服務商專門的團隊處理，相信大家都很願意把硬體設備等等投資在雲端上，但最後還是要提醒一句，如果是高運算、長時間待機需求，建議是直接租用EC2會比較划算，無伺服器架構還有一個大缺點，Cold-Start，筆者團隊有試著繞過VPS啟動的步驟，減少了2/3的啟動時間，但安全及穩定性上有所取捨，有機會針對減少冷啟動時間來寫一篇文章，\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2532/1*UVYAT7_mtodK07lhNti30Q.png","plink":"https://chenkuansun.github.io/2019/06/21/AWS_Serverless_01/"},{"title":"LIFF 與 Angular 共舞 — 實作 — 02","date":"2019-06-16T18:46:25.000Z","date_formatted":{"ll":"Jun 17, 2019","L":"06/17/2019","MM-DD":"06-17"},"updated":"2020-04-13T23:55:01.576Z","content":"由於上一次只教大家用基本功能來取得使用者資料，這次來練習做一點回家功課，文字辨識。\nLIFF 全名是 LINE Front-end Framework，是用來打造一些在LINE聊天室內打開的Web App平台。由於我在生活中常常要傳一些資料給朋友，都要照著資料打實在是懶惰，科技來自於惰性，我就想要來開發看看文字辨識，並可以使用傳送文字到聊天室的功能來讓大家熟悉一下LIFF的功能。\n實作：這邊假設大家都已經遵循我上一篇文章，都設定好基本環境狀況下開始。\n這邊介紹一下我們將要串進來的套件：**Tesseract.js，它是由著名的OCR引擎**Tesseract OCR engine所接出來的ECMAScript套件（我怕被告不想用商標～），不知道Tesseract的人可以去查查他的淵源，總而言之他已經被Google收養了，也接入了LSTM的機器學習等技術，是一個強大的OCR引擎，甚至有些人拿它來破解驗證碼。\n我們要使用Tesseract的話建議用npm install 安裝(感謝urakozz幫大家打包好易用的TS檔）\nnpm i -S tesseract.ts tesseract.js接下來就到要使用的AppComponent.ts內加入引用\nimport { Tesseract } from &quot;tesseract.ts&quot;;由於我們是要做在LIFF裡面所以我們需要初始化LIFF，打入liff直接點選init，就會自動填入初始化的init。\n因為我們需要使用者拍照或上傳圖片來做辨識的動作，所以我們在Template內加入input，並綁定他上傳完圖片需要呼叫的事件。\n&lt;input type=&quot;file&quot; accept=&quot;image/*&quot; capture=&quot;camera&quot; (change)=&quot;uploadImage($event)&quot;&gt;改掉範例的程式會長這樣，\nstatus是目前整個辨識狀態\n\nprogress是辨識的進度\n\nmessage是辨識完之後將結果填入的部分\n\n接下來我們要呼叫Tes的API\nTesseract.recognize(img,&apos;eng&apos;)\n\n    .progress((p) =&gt; {\n\n        this.status = p.status;\n\n        this.progress = p.progress * 100;\n\n    })\n\n    .then((res: any) =&gt; {\n\n        console.log(res);\n\n        this.message += res.text;\n\n    })\n\n    .catch((e) =&gt; { this.message += e.message; });其中 img的部分是我們要傳入的圖片，eng是要辨識的文字，API是根據ISO 639–2 的規格去訂語言的，繁體中文是chi_tra，目前我們先從簡單的英文開始（雙語言的部分似乎有些BUG所以先不在這裡實作。）。接下來我們來測試一輪，打入npm start\n接下來上傳一張圖片來測試，就直接上傳上面這張截圖\n可以發現除了非英文的部分以外，辨識能力極高，\n當然也加入了中文(chi_tra)來測試，不過辨識能力似乎普普，但至少看起來能用就好。我們接著來使用傳入聊天室的功能。\n加入確認按鈕，如果想要掃完不確認就直接傳的話可以直接在API裡實作就好。\n接下來打入liff就會有sendMessages的建議，直接選擇。\n我會假設使用者傳完就要回去繼續聊天等等，就直接幫他關閉這個LIFF視窗，如果想要讓使用者自己關閉的話就不用加入closeWindow那段。直接npm build專案部署到LIFF測試效果（不知道怎麼部署可以參考我上一篇文章）\n隨手拿手邊的書直接拍，然後測試英文的效果（請忽略沒有CSS排版），如果可以結合雙語言的話應該就不太會有亂碼的情況發生。接下來點送出讓他幫我們傳入聊天室。\n傳入聊天室很意外的發現，他有幫我們做一些排版的動作，而且原圖是順時針90度，沒有被影響到。既然都了解可以幫我們排行列的話，可以考慮做依據換行做split的動作傳入Array裡面做出選項，讓使用者點選想傳出的訊息之後再按送出鍵的進一步應用。\n補充：中文的辨識度還很差，可能要另外導入模型才行。\nStackblitz範例連結(直接抄程式碼，因為OCR TS套件沒法在上面用的樣子）angular-liff-demo-ocr - StackBlitzStarter project for Angular apps that exports to the Angular CLIstackblitz.com\nLIFF可以結合很多LINE沒有內建的功能，打造出更生動的SPA來跟使用者互動，不過這次雖然結合OCR引擎，但實際上還是調用OCR API的方式，所以在下載訓練過的辨識模型跟辨識過程都會需要花時間，建議想做到整合型的APP應該要將Tesseract Open Source OCR Engine包在整個SPA內，並直接導入雙語言來讓使用者可以更快速的掃描出想要的文字內容並利用LIFF的SendMessage ＡAPI來傳進去LINE內，節省更多打字的時間。如果我有想到更多應用的話，敬請期待嚕～\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2000/1*njRRts36H6DKD1gDh_H3NA.png","plink":"https://chenkuansun.github.io/2019/06/17/LIFF_02/"},{"title":"AWS Deepracer RL競賽實戰心得分享","date":"2019-06-12T16:46:25.000Z","date_formatted":{"ll":"Jun 13, 2019","L":"06/13/2019","MM-DD":"06-13"},"updated":"2020-04-13T23:55:01.571Z","content":"近期內AWS推廣Deepracer挑戰賽特別火熱，究竟是什麼東西讓如此著迷呢，接下來細細聽我分享。\nAWS Deepracer League\n最近非常火紅的屬自動駕駛、機器學習了，但這些東西對於一般人來說實在是有距離感，也無從入門，所幸Amazon在這方面替大家做了很多工，跟Intel NervanaSystems的Reinforcement Learning Coach專案合作，替大家免去了演算法及相關特徵工程的繁雜，整合使用ROS系統方便更快部署模型到實體車輛上，也提供了Gazebo訓練環境供車輛訓練，這些在增強式學習領域都是工程師的重要工程，AWS替大家把服務整合了在一起，提供了一個Console面板，後面的繁重工作都幫你處理好了。\n今天你只要訓練好模型，然後下載模型，放到車子上，就可以完成一台小車自動駕駛的夢想（想想看以前的爆走兄弟卡通，他會自己跑是多麽浪漫的事，只差不會噴火了），話不多說，直接來介紹今天主角：AWS Deepracer Car\nAWS Deepracer Car本身是一個1/18的實體車輛，他的優點在於本身是一台類似Donkey Car ，但是運算能力超群，車輛規格如下（取自AWS）：\n\n汽車：1/18 比例 4 輪驅動並加裝引擎越野卡車底盤\n\nCPU：Intel Atom™ 處理器\n\n記憶體：4 GB RAM\n\n儲存體：32 GB (可擴充)\n\nWi-Fi：802.11ac\n\n攝影機：採用 MJPEG 的 4MP 攝影機\n\n軟體：Ubuntu OS 16.04.3 LTS、Intel® OpenVINO™ 工具套件、ROS Kinetic\n\n驅動電池：7.4V/1100mAh 鋰聚合物\n\n運算電池：13600mAh USB-C PD\n\n連接埠：4x USB-A、1x USB-C、1x Micro-USB、1x HDMI\n\n感應器：整合式加速度計和陀螺儀\n\n一台車該有的什麼都有了！就差一顆炙熱的心（還要充飽電才行）。\n關於一些體驗營等等前置教學文章在LINE工程師在參加完體驗營的時候有寫了一篇很詳細很棒的文章（連結：AWS DeepRacer 自動駕駛賽車模擬實驗營心得分享），這邊主要講一些調整參數及比賽的心路歷程：\n實際上AWS舉辦的這個競賽分為實體跟虛擬兩類別，都是在AWS線上訓練，之後訓練好的模型可以下載下來部署到實體車輛上面（目前都尚未發售，除了在比賽中獲得車輛以外基本上都是要預購），而在實體競賽中是以下載到USB，透過插入USB，並使用iPad連結到車子的Dashboard方式控制車子。\n\n在實體比賽的時候也是讓你拿著iPad控制最大速度來操作；虛擬競賽的時候則是直接提交訓練好的模型，由評估系統來試跑車輛。\n官方獎勵\n而最大獎勵就是去拉斯維加斯機加酒全包的集結各地冠軍來比賽，算是AWS一年一度的最大盛事，但本人胸無大志，只想要男人的浪漫小車（前十名皆有一台小車當獎勵或同值獎品，一切以官方說明為主）。在參加完5月份的Deepracer體驗營之後，驚艷了一下，因為除了在專業課程以外，從來沒有在外面場合聽到Reinforcement Learning這麼完整的解說跟教學，獎勵等等的影響因素都在Keynote中舉重若輕的表明了，事實證明AWS很重視他們對於RL領域的推廣及賽事，也證明了他們在AI的軟實力。\n\n在結束體驗營的時候，跑去問了又高又帥講師跟Amanda相關內容，他們提到有拉斯維加斯的時候感覺就還好，但是提到前十名都有一台小車的時候，心裡就開始蠢蠢欲動了（因為自己有一台小鴨車，根本提升好幾個等級）。\n\n回到家之後立刻開啟了上課的內容，研究起可以更改的超參數跟最近比賽的資訊，看到London Loop虛擬競賽剩下兩週，心想，不然就訓練看看好了，結果第一次訓練8小時提交之後大概13秒左右，結果提交的時候需要我填入名字，我原本想說寫個CKSun，後來想想，覺得全世界都不太認識台灣，然後台灣很多軟實力超強的人都沒被發現（除了大舉來台幾個科技巨頭以外），想說推廣一下台灣跟台北，就打個Taiwan-Taipei-CKSun，\n\n就這麼進入了前50名？？？？\n\n當然50名不是目標，為了讓我寫的台灣台北這幾個字可以讓大家看到（全世界即時的排行榜），接下來就是增強式學習的基本幾個心法，我打開了ROBOMAKER，研究了地圖，發現有些彎是可以不用刻意去彎，開了基本的地圖先觀察Agent的實際行為，他會刻意的去找中線，也是因為我一開始用預設的獎勵函數所致，所以我特意把獎勵函數設定成：\ndef reward_function(params):\n    &apos;&apos;&apos;\n    Example of rewarding the agent to follow center line\n    &apos;&apos;&apos;\n\n    # Read input parameters\n    track_width = params[&apos;track_width&apos;]\n    distance_from_center = params[&apos;distance_from_center&apos;]\n    all_wheels_on_track = params[&apos;all_wheels_on_track&apos;]\n\n    if all_wheels_on_track and distance_from_center &lt;= (0.3 * track_width):\n        reward = 1\n    else:\n        reward = 1e-3  # likely crashed/ close to off track    \n\n    return float(reward)其實就是AWS預設的第三個獎勵函數，而訓練出來的結果就是看起來很不在意中線，但是會很在意出軌，我在這邊常常跟Deepracer社群的人說，獎勵越簡單越好，越是刻意的去寫複雜的獎勵就有點像是過度教育一個寵物，越是故意去引導，反而會讓他陷入一個你認為好的方向的迷思，有時候Agent他會自己找到最好的答案，要保留最多的空間讓他探索，限制掉那些規則之外的東西就好了。\n)圖片出處\n這個想法說真的見仁見智，我所謂簡單的意思不是Reward Function越少行越好，而是訂定獎勵的時候要大方向，剔除掉不必要的細節，在適當的地方放上懲罰，而不是為懲罰而罰。正所謂 Less is more, simple is power.\n\n調整了獎勵函數之後，接下來就要思考動作空間的問題，Deepracer的動作空間選擇很少，就是幾個排列組合而已，動作空間越大，探索的範圍代表越多，也就代表Agent要在這些動作空間中找出規律的機會越少，總而言之，訓練時間就要拉很長，而動作空間大的好處是：操控越細微、可以在微小的弧度中修正角度等，但是壞處倒是比較多，訓練時間極長，而且操控越細微代表容錯率低（敏感）等，所以如何在動作空間大小中做取捨，還是要在腦海裡用這些模擬出一個完美的賽車應該有什麼樣的跑線（不是頭文字Ｄ，這裡沒有水溝蓋）。\n\n而我們必須在這些完美跑線跟動作空間做出一個好的平衡，上面的表格有細微的修正（10度）有大幅度的修正（30度），還有從中取捨的修正（小轉彎），基本上已經滿足轉彎需求，而速度這方面需要多方面測試，速度跟每秒判斷次數極度相關。因為每次判斷完一次車子就會做一個動作直到下一次判斷，也就是說，如果每秒判斷10次，而一秒跑5公尺的話，等於一秒就跑了50公分，那代表著，這次他要轉30度，他至少要跑50公分的距離才會做出下一個動作，那就不只是30度那麼小的角度了。\n綜合上述思考過後，我選擇了直接最高速度去訓練，經過訓練了2個小時之後，有開始收斂的現象，就開始用調整參數的方式處理訓練步驟，這邊非常建議新手從做表格開始，每次訓練都做一個超參數的表格，剛開始的幾個小時都是從0.0005 Learning Rate開始，看獎勵函數慢慢降低，但不要太低，因為Reinforcement Learning最怕Overfit，適度泛化模型是最好的選擇（選其他地圖適當訓練等等），也很高興的模型開始學習如何去找出最佳路徑來過彎道，接下來我就提交了訓練了2+2+8個小時的模型上去，\n\n結果一舉沖到了第五名，突然衝到世界排行榜上的感覺真的很棒，因為前面就說想把台灣掛上去的夢想突然被達成，接下來我就想要再接再厲，於是我再度微調Reward Function的距離從0.3調到0.4，拿掉了ALL on Track（全部輪子不一定要在賽道上），接下來也是2+2小時（記得調高Learning Rate)的一直觀察車子行為，然後再度提交，\n\n真的有效的感覺，但是穩定度變差了，不一定可以跑完整圈的次數變多了（因為賽道判定較為嚴格，只要兩個輪子在白線外，車子中心稍微外偏就算未完成），但在高速與穩定者兩方面必須做出取捨，於是調低學習率繼續訓練讓他習慣這個步驟，直接丟出8小時的長時間 Batch_size大（穩定更新）的訓練，也順便去參加Computex展，然後參觀期間就順手遠端上傳一個模型，結果還真的衝進第一領先，\n\n頓時嚇到，因為夢想好像都達到了，但是比賽也未結束，我還想看看模型極限在哪邊，於是繼續縮進學習率訓練，隔天不知道是不是被我氣到還是什麼（他們搞不好都還在穩定訓練），突然一堆強勁的對手衝過我，不過我也不甘示弱的再丟出新的訓練成果，結果也就進步0.5秒。比賽尾端果真進入白熱化階段，壓力真的不是普通大，很怕被刷出排行榜。\n\n而然，比賽剩下最後兩天半，結果遭遇了ROS公用庫被攻擊的問題，整個ＡAWS Deepracer的訓練任務跟評估任務全面停擺兩天，突然覺得是被陰了還是屎到不行…，後來恢復正常的時候已經剩下不到24小時的時間，突然就發現前三名都還有持續提交模型（？），我的模型預估已經到極限了。\n索性就放棄第一，因為前後訓練的金額達到700美金之多，沒有像他們一樣是有組團那麼多資源，一個人參賽資源還是有限，後來比賽結束之後，大家也有在討論，才發現他們有辦法更改最高速度跟本地訓練，有一些技術可以達到一樣訓練目的，不過這個最高速度在比完這次虛擬賽之後也全面開放到8 m/s，有時候資訊不對稱也會是比賽的弱點之一。也因此決定寫這篇文章，讓大家清楚知道我是如何訓練好一批強勁的Agent，也想讓更多的台灣好手能夠被看見，也許有些人天生有資源，但是這些並不重要，這次本魯能夠靠一個人拿到那麼前面的名次，代表你有實力，很多東西其實沒那麼重要。\n實體競賽心得：\n說真的這次去Summit玩看看實體的小車，哇！真的好多東西跟虛擬競賽的不太一樣，原本想說去參觀（我絕對不會說為了贈品），沒想到手有點癢就把之前訓練的幾個實驗模型丟下去跑跑看，結果全部都爆出軌了，\n其實大多跟上週更改每秒判斷次數有關，原本車子判斷次數每秒十次改為15次，這個差別蠻多的，很多訓練有素的模型（含虛擬第四名的模型）在實際賽道上跑起來很悲劇。\n但是這次倒是觀察到很多Agent的行為，認知到在實體賽道上獎勵的設定要以中心線為主，作為整體的策略，如果用白線作為邊界去訓練，很容易因為光線晃動問題而判斷失誤，因此以中心線配合黑色底道路是最佳的選擇。\n也因為這次Summit了解到國內很多人對於這方面很熱心熱血，趨勢科技也自組了一個團隊來玩，交通大學也有一群熱血學生，真心希望他們可以拿到冠軍出國比賽，而不是被外國人搶走（這次社群有幾個從國外跑來比的）。\n結語：最後要非常感謝AWS總經理跟Amanda（正妹推廣者）以及這次比賽讓我亂試模型的工作人員（我都調100速度不要恨我…），這次去玩還真的受寵若驚，從不知道整個AWS Taiwan的人都有關注我的線上比賽（能不能補助一點呀～啾咪），這個真的有感動到我，以為我是一個人，原來背後有許多人默默支持我，也感謝這次Warren補助我訓練經費，不過真的累了不想訓練太多模型去跟學生們搶獎品，因為第一個虛擬賽道的積分已經拿到，集滿六個其實前18名去拉斯維加斯也沒問題，但是做這系列比賽真的很好玩卻頗累的，還有其他規劃要同時進行，就看後續還有沒有心力繼續比下去了。\n哎呀還要補充一點，因為虛擬前10名的關係有獲得一台小車（還沒拿到），之後應該會有計劃跟AWS借一下場地來讓大家體驗一下實體賽車（沒有實體車的可以用Donkey Car玩玩看）。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2000/1*F63CNm2iTQUbgBGzLt-1Yg.png","plink":"https://chenkuansun.github.io/2019/06/13/AWS_DeepRacer/"},{"title":"LIFF 與 Angular 共舞 — 實作 — 01","date":"2019-06-10T16:46:25.000Z","date_formatted":{"ll":"Jun 11, 2019","L":"06/11/2019","MM-DD":"06-11"},"updated":"2020-04-13T23:55:01.576Z","content":"上上週去LINE Developers Meetup參加了LINE新的技術分享會，除了超級好吃的食物跟超棒的場地外，不外乎就是一堆神人分享技術，跟超正主持人（？），根本是視覺味覺饗宴。\nLIFF 全名是 LINE Front-end Framework，是用來打造一些在LINE聊天室內打開的Web App平台。由於剛推出沒有很久，似乎還沒有很多人意識到這個平台的價值性，現在還可以結合LINE Things控制IOT物聯網，結合SPA網頁做官方帳號額外LINE功能擴充等等。\n實作：這邊帶大家實做一遍用Angular 結合這次LINE API Expert — Will 保哥打造的LIFF Code Snippets套件打造一個完整的LIFF Web APP。\n這邊我們從建立一個 Angular APP 開始：首先打開VS Code，然後假設大家都會基本的Angular，新增一個ng專案\nng new liff-app進入資料夾之後，下載保哥打造的擴充套件LIFF Snippets，也可以直接到擴充套件輸入保哥搜尋，通常是前幾個。\n打開之後可以看到保哥的說明：\n進到專案裡面要先先到index.html加入一行liffsdk，這樣才可以執行LIFF相關套件，只要輸入liff\n就會出現Code Snippet，就會自動填入下面這個套件\n&lt;script src=&quot;https://d.line-scdn.net/liff/1.0/sdk.js&quot;&gt;&lt;/script&gt;在app資料夾底下加入app.d.ts檔案（根據使用狀況而定），在裡面打liff之後會看到擴充套件帶來的方便之處，建議清單\n這時候點liff-tsd\nMagic!!保哥已經幫大家打好型別定義了。覺得神奇可以去點五顆星給保哥支持一下嚕。\n接下來進入component的TS檔我們先來定義一個profile，型別是LIFFUserProfile\n要開始使用LIFF就要先把liff加到初始化裡，這時在OnInit一樣打入liff\n由於我們是要拿使用者資料，所以點選profile，事實上沒有要取得使用者資料的話點上面那個 liff-init 就可以了。\n註解裡都有API詳解網址跟可以取得的各Data屬性，還可以獲知當前View的大小（通常是你自己在LIFF Channel設定的除非這個網頁有不同的Liff APP進入點，就可以根據View等等屬性切換功能）\n接下來我們實作一下，如果我叫CK Sun，就會跟我說Hello，如果我不是CK Sun，就會跟我說HI。\n由於型別定義的關係，我們在Template輸入變數的時候就會很方便讓我們選擇。\n這樣基本的程式碼已經完成，但在LIFF裡有個限制就是Endpoint必須是Https開頭的加密網址（如果你都會設定就直接跳到LIFF環境設定），這時候我們方便開發就會推薦大家裝一個東西：Ngrok，按照指示註冊安裝完之後，把下載的ngrok加入環境變數，事實上Mac使用者可以用\nbrew cask install ngrok直接安裝（記得在官網複製Token值設定），然後推薦大家直接裝live-server來啟動伺服器，如果直接用ng-serve，請記得用— disable-host-check來避免用不同host進入Angular App阻擋的問題。\nng serve --disable-host-checklive-server安裝方式很簡單：\nnpm install -g live-server啟動伺服器之前要先Build專案，輸入以下指令來執行\nng build --prod接下來Angular CLI會在dist資料夾底下建立好專案的production版，直接打下面這行（記得替換{app-name}成你的app名字）在liveserver上執行\nlive-server dist/**{app-name}**/會出現網址代表成功\n接下來就是用ngrok導向本地端伺服器，8080是根據開起來的port\nngrok http 8080成功會出現：\n可以先打開https開頭網址測試是否有連線成功。並記好這段連結。\n接下來進入LIFF環境設定階段：首先進入LINE Developers然後點選登入，第一次登入的會要求你註冊開發者的登錄資訊。\n\n*[LINE Developers](https://developers.line.biz)*登入之後，可以看到後台頁面，由於我已經創建一個LINE channel，所以頁面中會有，沒有的人請按**Create New Provider，接下來會出現**\n點選Messaging API\n請先點選Messaging API頻道來創建頻道。接下來跟著說明把資訊填入之後，創建完之後進入剛創建完的Channel頁面\n並往下滑到底會有QR Code可以自己加入機器人。\n掃完之後可以加入自己的機器人，可以說個 Hello，然後在QR Code下面有個Basic ID，可以透過下面連結到管理頁面。可以點選聊天TAB（聊天模式請從機器人改成聊天訊息）可以跟自己對話。\n[https://manager.line.biz/account/](https://manager.line.biz/account/)@你的機器人ID，回到剛剛的Channel頁面然後點選LIFF TAB\n可以看到新增的頁面，然後點Create a new LIFF App創建新的Web App\n可以看到有三個Size，分別是Full，Tall，Compact，如下圖\n![由左至右Full，Tall，Compact](https://cdn-images-1.medium.com/max/2250/1*k3P04u1pSpgDaNlYRhwkMA.png&quot; style=”max-width: 100%;”&gt;由左至右Full，Tall，Compact\n輸入Endpoint，就是上面我們Ngrok提供的網址或是你自己的網站也可以 。BLE的部分等有實做的時候再來講解，先丟概念圖：\n就是一個支援外連裝置的應用，可以做一些Web APP驗證完使用者的UserID然後就透過BLE方式啟動藍牙裝置等等。\n接下來點選確認之後，複製LIFF URL後面的line://app/xxxx。到聊天機器人的頁面點選聊天，把URL貼給自己，打開它\n會先驗證是否讓Web App取得資料按下許可就會進入APP如下圖所示：\n由於我們剛剛程式有設定好：\n如果是CK Sun就說Hello，如果不是完全符合的就說Hi，\n接下來試著取看看其他資料如UserID\n再來開啟測試：\n這樣就可以試著做其他應用用途，實際上API還有很多種，有興趣的人可以到LIFF API referencet查詢。\nAngular 與 LIFF 共舞 (LINE Developer Meetup)保哥上課KeynoteStackblitz範例連結angular-liff-demo - StackBlitzStarter project for Angular apps that exports to the Angular CLIstackblitz.com\n結語目前簡易的應用可以先介紹到這邊，目前正在構思如何在LIFF Web App 導入TF.js的好玩應用，讓大家玩玩在手機上跑應用然後丟訊息到聊天室的做法。能夠這麼迅速開發還是要感謝**LINE API Expert — Will 保哥**打造的LIFF Snippets能夠很方便的取得各種需要的資訊，減少去翻文檔的次數，如果這些文章有幫到你的話請多給我掌聲，如果覺得工具非常好用的話可以去LIFF Snippets頁面點五顆星，大家有更實用的TF建議應用可以發信給我構思。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2000/1*GKBCjnvRhgCofYgCcFpShQ.png","plink":"https://chenkuansun.github.io/2019/06/11/LIFF_01/"},{"title":"JupyterNotebook with Anaconda 導入Module老問題","date":"2019-02-02T18:46:25.000Z","date_formatted":{"ll":"Feb 3, 2019","L":"02/03/2019","MM-DD":"02-03"},"updated":"2020-04-13T23:55:01.575Z","content":"在windows常常遇到Jupyter Notebook import不到模組，可是在純命令列中用Python卻一直都是正常的導入，到底問題在哪裡。\n每次都要Google，每次遇到的答案不是說Conda install重裝等等，一堆月經文加月經答案。只好動手寫一個比較完整的作法。\n先來解析為什麼都抓不到模組。打開一個新筆記本，輸入\n!jupyter kernelspec list會發現Python核心檔案是吃到Windows本地的Python，而不是我們創建的虛擬環境核心檔案。\nAvailable kernels:\n python3 C:\\Users\\XXXXXX\\AppData\\Roaming\\jupyter\\kernels\\python3為什麼呢，因為有可能是原本Windows有裝了Python套件跟JupyterNotebook(像我就有很多專案，需要各種不同的執行測試)，然後在Anaconda 裡直接輸入套用環境\nactivate vir-env然後開啟Jupyter Notebook會開到自己系統裡面的，Windows不像是Linux系統那樣可以用source activate vir-env那樣開啟一個全隔離的環境。因此找來找去找到一個很棒的Jupyter Notebook核心管理包，只要在要開Jupyter Notebook的環境下打\npip install environment_kernels(選用)如果以前沒有做過設定檔，輸入以下指令生成一個Jupyter Notebook設定檔，生完之後會出現設定檔路徑\njupyter notebook — generate-config到 jupyter_notebook_config.py路徑下，加入兩行\nc.NotebookApp.kernel_spec_manager_class = &apos;environment_kernels.EnvironmentKernelSpecManager&apos; c.EnvironmentKernelSpecManager.conda_env_dirs=[&apos;~/.conda/envs&apos;]儲存之後，打開jupyter notebook，在kernal裡面會找到你所有虛擬環境的核心檔，只要選擇你的環境，就可以正常使用了。\n如果想了解更深入的內容，可以到作者Github上看解說。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/2752/1*WgYIbhfkPlRCqxPb23OzCQ.png","plink":"https://chenkuansun.github.io/2019/02/03/JupyterNotebook/"},{"title":"Unity ML-Agents 第三章：訓練範本","date":"2019-02-02T18:46:25.000Z","date_formatted":{"ll":"Feb 3, 2019","L":"02/03/2019","MM-DD":"02-03"},"updated":"2020-04-13T23:55:01.633Z","content":"上一章我們實現了載入官方訓練好的數據，這一章節我要來介紹如何自行訓練官方範本的模型，包含可視化訓練數據，調整訓練環境的參數等等。\n基本上本章節分三加一種方式：\n從編輯器直接執行PY訓練檔做訓練。\n\n從建立好的環境執行文件接入PY訓練檔做訓練。\n\n從ML-Agents Toolkit提供的Python API做測試。\n\n從ML-Agents Toolkit提供的Python API做訓練(進階)。\n\nUnity提供了一個很好的方式，請設計場景的人設計好資料接口，可以直接從已經打包好的執行檔直接接入模型來做訓練。而進階的部分是從Jupyter直接打自己的模型接API做訓練，這個牽扯到Unity調用的部分，留待後續章節講解。\n基本上要開始之前我先假設讀者是重開命令列了，所以從頭講起，先開好上一章的場景，打開UnityHub直接點UnitySDK，等開好SDK之後，我們要先來做由學習模型控制的準備，首先選中3D小球的場景\n接著點場景物件視窗的Ball3DAcademy，屬性視窗會出現相關選項\n屬性視窗會中有一個選項，把Control打勾(如果沒有勾就是預設給丟進去的已經訓練好的參數控制)\n然後打開命令列，CD到你的ml-agents目錄底下，輸入(Windows使用者前面的conda不用輸入)\n1conda activate ml-agents使用編輯器進行模型訓練這邊講解最基礎的方式做訓練，套用官方的模型。\n講解一下整行指令\nmlagents-learn &lt;trainer-config-path&gt; --run-id=&lt;run-identifier&gt; --train是指訓練參數的設定檔位址，要丟Path進去，官方預設的設定檔在\nconfig/trainer_config.yaml打開之後可以看到預設的模型是使用PPO演算法，HyperParameter也都在裡面，調整的方法留待後面講解，基本上要調整的設定都是放在這個檔案。\n是指這次訓練的名稱，自行指定，建議都加上日期跟序列，這樣比較好理解。\n(選用) 如果加上–load就會載入預訓練好的繼續訓練，沒有設的話就會是隨機初始係數。\n(選用) 如果加上 — env=可以設定使用執行檔進行訓練，沒有設的話預設是用編輯器來訓練。\n後面的train是代表這次是學習訓練，如果沒有去設定會是凍結係數的狀態，只是用來看訓練結果用的。\n接下來就訓練一次預設設定的訓練過程，打入\nmlagents-learn &quot;config/trainer_config.yaml&quot; --run-id=&quot;train_3dball_01&quot; --train(選用)Windows用戶可能會出現no module named win32api. ，打以下指令就可以解決。\npip install pypiwin32如果執行成功會提示使用的資源，然後要你按下編輯器裡的Play，這時候進到Unity編輯器裡按下撥放鍵(太久沒按會出現ERROR，重新執行即可)\n這時候就會開始一輪新的訓練，在執行過程中，每跑完一個1000(summary_freq)值就會總結一次\n直到到達max_steps停止，預設(config/trainer_config.yaml)是50000步，\n從結果中可以看到平均獎勵從1.2到達98，當然，還沒到達最佳解，還在波動，所以我們之後可以微調(trainer_config.yaml)參數讓他更快收斂跟到達底部，在執行(另開同目錄的命令列)或是結束的時候可以輸入\ntensorboard --logdir=summaries這樣會開啟一個數據網址，是輸入summaries資料裡的訓練數據\n直接在瀏覽器列打開，預設是6006，請看上面的狀態輸入。\nlocalhost:6006這樣就可以看到可視化數據，如果前面有訓練過的話會一起載入，就可以比較兩種參數的差別。\n接下來載入訓練好的模型，進到編輯器裡，把ml-agents/models底下訓練好的模型資料夾(名稱就是上面指令的訓練名稱)拉到編輯器的目錄下，建議都拉到TFMODEL較容易管理。\n接下來點Brains裡的3DballLearning，可以看到屬性視窗有個MODEL\n把訓練好的模型資料夾底下3DballLearning的拉到MODEL之後，點一下MODEL裏頭的文件。確認是指向訓練完的文件。\n接下來點場景物件裡的Ball3DAcademy，在屬性是窗內把Control取消勾選。\n接下來點選撥放就可以看到訓練成果了。\n另外有個更快的方法，就是直接用預載入模型的方式去LOAD，記得把trainer_config.yaml的learning_rate改成0，這樣就不會學習，然後拿掉–train，在 — run-id後面加上預載入的模型，加上 — slow的話就會以比較真實的時間去跑。\nmlagents-learn &quot;config/trainer_config.yaml&quot; --load  --run-id=&quot;train_3dball_02&quot; --slow這指令原本用來載入預訓練的模型，這是一種活用的方法。\n這邊預祝大家訓練愉快~ ，另外覺得這些流程有幫助到你的話多給我幾個掌聲～可以連拍到50下唷～有問題可以在下面留言，我盡可能幫忙解答。\n(選用)打包成執行檔訓練接下來教大家怎麼打包，打包之前先打開File&gt; Build Setting\n點選左下角的Player Setting\n接下來勾選Run in Background，確定Display Resolution Dialog選擇Disabled\n然後確認小視窗裡面的場景是不是空的，如果不是要確定只有選中要訓練的場景，然後按Build，會問你要存在哪，我們就設定在目錄底下的env(請自己創一個)，然後取名3Dball，然後按確定會開始建立。\n建立完成後會出現3Dball.app，接下來只要開始測試\n因為放在目錄底下的env/3Dball.app，所以把這段加上去，就會發現開始訓練了。\nmlagents-learn &quot;config/trainer_config.yaml&quot; --run-id=&quot;train_3dball_04&quot; --env=&quot;env/3Dball.app&quot; --train(選用)也許有人問說為什麼視窗這麼小，因為這是訓練視窗，盡量不耗費資源為前提，如果想要更高解析度來觀察的話可以在Build之前設定，在場景目錄內選Ball3DAcademy，屬性是窗內有一個Training Configuration，裡面有個長寬設定，設定成自己想要的質就好，然後下面有Time Scale，是指訓練加速的程度，FrameRate是FPS。\n(選用)使用Python API檢查及測試訓練環境這邊從官方提供的Notebook範本來做講解，windows用戶先看我這篇文章!!\n接續上一個命令列指令，輸入下面指令打開jupyternotebook\njupyter notebook接下來畫面會出現一行網址，複製下來貼到瀏覽器網址中打開：\n然後從網頁中找到notebook資料夾下的getting-started.ipynb，打開他\n接下來會看到這個畫面\n(選用)基本上這就是PythonAPI接入Unity引擎的介紹，從\nfrom mlagents.envs import UnityEnvironment可以知道，這個是整個API最重要的地方，在environment.py中定義了UnityEnvironment 這個類別是用來控制整個Unity的環境，連接與溝通的主要方法。在brain.py中定義了BrainInfo是整個Agent的所有數據來源。而BrainParameters就是在Agent中保存的數據類型。\n一開始我們先從編輯器裡處理，所以看到Start the environment底下有個\nenv = UnityEnvironment(file_name=env_name)要修正成\nenv = UnityEnvironment(file_name=None)(選用)相反的，如果想要直接看打包好的環境的話，就是透過編輯器build完的執行文件，在第一個Set environment parameters下定義\nenv_name = &quot;../envs/3DBall&quot;把後面的字串改成執行文件的Path即可。\n接下來我們要開始執行一次訓練過程，點到第一個Tab，然後點上面的Run(shift+Enter)，一格一格執行。\n接下來到開啟環境這個如果是用編輯器訓練會提示你按下編輯器裡的播放按鈕，進到編輯器點播放(太久沒按會出現無回應的錯誤，再重新點那個單元再Run就可以了)\n編輯器點完撥放會出現抓取到BrainInfo的訊息，目前可以知道我們用一組大腦訓練，如果想要比較不同模型參數訓練可以設定兩個大腦，一組訓練一半，可以觀察。\n基本上Examine the observation and state spaces，這個單元格會重置整個環境，是用\nenv_info = env.reset(train_mode=train_mode)[default_brain]可以發現重置完之後會告訴您觀察到的狀態，下面的單元格是開始一輪新的模擬環境測試，一樣點Run，可以發現小球開始做動。\n以上是用Jupyter Notebook來檢查環境，當然想要直接在上面跑模型的人也是可以從這個接口接入模型，並透過API傳送Action給Agents，不過這個進階的部分留到後面的章節再解釋。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n","thumbnail":"https://cdn-images-1.medium.com/max/5760/1*Y6bT3Fd2reyoqOXa35f2Mg.png","plink":"https://chenkuansun.github.io/2019/02/03/Unity_ML_03/"},{"title":"Unity ML-Agents 第二章：範本介紹","date":"2019-01-31T18:46:25.000Z","date_formatted":{"ll":"Feb 1, 2019","L":"02/01/2019","MM-DD":"02-01"},"updated":"2020-04-13T23:55:01.632Z","content":"經過上一章的安裝，這次直接帶大家進入UnityML的世界，在本章我們會來開啟 Unity ML-Agents Toolkit中的經典範例-3D小球來介紹使用預訓練好的模型套用在範例專案上。\n專案環境設定這邊環境就用最新版的2018.3.3f1，安裝完成後打開Project，（點Open）\n進到ml-agents/，點UnitySDK直接按打開就可以了。（截圖是OSX ,基本上往後步驟兩個作業系統操作幾乎一樣）\n這邊他會問版本問題，不用理他直接按open，後面會問要不要升版本也是按升級。(windows版按continue，會有一些包的問題也都是直接按continue)\n進來之後會看到這個畫面，如果是Uniy老手可以跳過下一段，這邊開始講解怎麼調整工作區到方便處理的位置。\n(選用)首先點上面的Windows&gt;Layouts&gt;2 by 3，就會看到跟我一樣的排列工作區\n(選用)然後關掉一個分區，接下來直接按著TAB直接拉到左邊(可視個人喜好調整)，\n(選用)最後會長這樣。\n接下來安裝上一章節說的 TensorFlowSharp，到下載好的目錄。點選兩下匯入\n點完之後會回專案然後載入會出現匯入的視窗，按import\n匯入完之後檢查最左邊的工作區，點ML-agents&gt;Plugins，看有沒有出現Computer資料夾，有的話代表匯入成功。\n接下來點Edit&gt;Project Settings…，打開專案設定。\n點開左邊的Player然後點選other Settings的選項會跑出一堆選項。\n拉到下面找到 Scripting Define Symbols的選項，在空格裡輸入\nENABLE_TENSORFLOW輸入完會自動儲存，記得勾選unsafe Code，因為有載入TFSharp的外掛，所以沒有勾的話會出Error，點右上角的紅色按鈕離開，接下來環境就設定完成了(Windows用戶要多一個步驟，要點File&gt;Save Project)，可以進入最基礎的3D小球範例。\n3D Ball接下來開啟3D Ball場景，打開左邊的目錄\nAssets/ML-Agents/Examples/3DBall/Scenes底下點兩下3DBall，就會出現如我下面的場景。\n載入預訓練好的模型打開左邊的目錄，到Prefabs下面點兩下Game，\nAssets/ML-Agents/Examples/3DBall/Prefabs右邊的工作區點Platform，然後屬性視窗會有一堆屬性，找到Brain屬性，點一下框框\n會發現目錄視窗跳出黃框，\n把左邊黃框那個資料夾裡的 3DBallLearning直接拉到剛剛點的那個框框內。\n之後點一下左邊目錄內的 3DBallLearning，會出現屬性。\n把TFMODEL資料夾裡已經訓練好的模型 3DBallLearning拉到屬性內的Model，這樣子你已經完成載入預訓練好的數據了，點選中間上面的撥放鍵就可以看到已經訓練好的板板穩穩地接住小球了。\n這邊概略講解一下原理，因為這12組可以視為一組小球+板板，我們剛剛在Prefabs裡可以發現一個關卡就是由一個平台含一個平面+一顆小球組成，而在這個平台裡我們有套用一組Agents腳本，然後在控制平台的Brain裡塞入一個Reinforcement Learning模型，採用Proximal Policy Optimization (PPO)演算法，有興趣的可以點入連結研究算法。\n模型在訓練的時候會一直調整參數，完成之後會存成一組.bytes檔，打開的話會看到一堆不是人讀的編碼，不過要注意的是，每次訓練的參數在TF不一樣版本下載入會有相容性的問題，建議在訓練完之後用打開命令列匯出一組環境檔來做為備份。(前提是有裝anaconda or miniconda)\nconda env export &gt; environment.yml輸入這個指令會得到一個environment.yml檔案，以後有需要用到同樣環境的時候只要在檔案存在的目錄下打\nconda env create -f ./environment.yml就會創建出一模一樣的環境了。\n基本上分成12組訓練是因為訓練的時候都是用同一組模型在訓練，可以分12路平行訓練，如果覺得電腦夠強的話，可以增加到50組，也可以加速運算，建議是採多路運算，然後速度保持在可以觀察的情況下，這樣才可以隨時調整，不然訓練了一天一夜之後發現弄錯了就還得重來。\n前面兩個章節都是引導大家建立好完整的環境來使用這些套件，下個章節開始會教大家用這些範本來訓練自己的模型。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n下一章：\nUnity ML-Agents 第三章：訓練範本","thumbnail":"https://cdn-images-1.medium.com/max/5760/1*lyyj3__WZn6unCBMksGIJQ.png","plink":"https://chenkuansun.github.io/2019/02/01/Unity_ML_02/"},{"title":"Unity ML-Agents 第一章：建構環境","date":"2019-01-30T18:46:25.000Z","date_formatted":{"ll":"Jan 31, 2019","L":"01/31/2019","MM-DD":"01-31"},"updated":"2020-04-13T23:55:01.632Z","content":"因為大家對於Unity的環境建置一直都有困擾(畢竟一直是BETA版沒辦法統一)，因此想到寫一篇標準的SOP流程來介紹如何安裝UnityML。\nWindows環境1：通過Anaconda安裝Python，下載並安裝Anaconda。這是一個很好管理環境的軟體(Container)，可以隨時切換環境來適應專案，請下載Python3.6以上的版本，Unity ML-Agents不支援Python 2。\n&gt;\n注意：記得勾選上面的選項加入環境PATH(建議全部勾選)。\n2：然後開啟命令列工具（Window+R打CMD）輸入\nconda create -n ml-agents python=3.6中間過程會問你要不要安裝新的軟體，打 y按ENTER，完成之後就會創建一個在Anaconda裡獨立的Python環境，為了能夠穩定測試各功能，用UnityML開發時的軟體版本會比較好。\n完成之後會出現\n#\n# To activate this environment, use:\n# &gt; activate ml-agents\n#\n# To deactivate an active environment, use:\n# &gt; deactivate\n#\n# * for power-users using bash, you must source\n#很明顯的只要輸入\nactivate ml-agents就會在你的當下直接轉換成ml-agents的環境，基本上你的命令列左邊應該會出現環境名稱，代表你已經在環境裡面了，這時候你做的事情都是用這個環境去執行的。\n3：安裝Tensorflow這邊分兩個部分，一個是有GPU的(我假設開發Unity的人都是用Nvidia GPU顯示卡)，而且都有顯示卡。一樣版本固定，除非官方有出新的指示說最新的TF版本，不然最好都用指定的(目前是1.7.1)，因為TF每個版本函數都會改，都有相依性問題。\npip install tensorflow-gpu==1.7.1(選用)沒GPU的這個指令\npip install tensorflow==1.7.14：下載Unity ML-Agents Toolkit整個工具包假設你有裝Git工具，在命令列直接打\ngit clone [https://github.com/Unity-Technologies/ml-agents.git](https://github.com/Unity-Technologies/ml-agents.git)然後等下載好之後進到這個目錄(注意，裡面還有一個ml-agents)\ncd ml-agents\\ml-agents(選用)假如你沒有git工具，直接到github下載他們的工具包，\n解壓縮完之後用命令列打 cd 解壓縮完的目錄\\ml-agents5：安裝工具包這邊要注意你的環境已經在上面說的ml-agents，而且命令列也在解壓縮完的目錄裡面的ml-agents(有兩層ml-agents\\ml-agents)。確認好之後打\npip install -e .6：安裝Unity3D官方指建議Unity 2017.4版以後的版本，這邊建議大家用UnityHub做安裝。\n7：完成建置\n在結束這章節以前請大家先下載好TensorFlowSharp，這個是用來載入預訓練好的模型用的。\n覺得這些流程有幫助到你的話多給我幾個掌聲～可以連拍到50下唷～有問題可以在下面留言，我盡可能幫忙解答。\nOS X環境1：通過Anaconda安裝Python，下載並安裝Anaconda。這是一個很好管理環境的軟體(Container)，可以隨時切換環境來適應專案，請下載Python3.5以上的版本，Unity ML-Agents不支援Python 2。\n統一都用Anaconda是因為安裝環境包都會比較方便。\n2：然後開啟命令列工具（Command+Space 打terminal.app）輸入\nPS: 目前支援的Tensorflow環境只有到Python 3.6，如果直接裝到3.7以上會找不到Tensorflow\nconda create -n ml-agents python=3.6接下來就會自動安裝好環境，安裝完成會出現下列訊息\n#\n# To activate this environment, use\n#\n#     $ conda activate ml-agents\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate載入環境\nconda activate ml-agents接下來安裝Tensorflow，因為OSX除了舊型的Nvidia顯卡以外基本上都沒有新版的，AMD的加速還沒有完整測試穩定性，因此我們還是用原本的CPU跑(這專案用顯卡加速也只是用CUDA做平行運算，沒有快多少)\npip install tensorflow==1.7.1(選用)如果堅持要用GPU加速的可以用這指令，如果是AMD的朋友記得去找關於AMD CUDA加速的套件\npip install tensorflow-gpu==1.7.13：下載Unity ML-Agents Toolkit整個工具包在命令列直接打\ngit clone [https://github.com/Unity-Technologies/ml-agents.git](https://github.com/Unity-Technologies/ml-agents.git)然後等下載好之後進到這個目錄(注意，裡面還有一個ml-agents)\ncd ml-agents\\ml-agents4：安裝工具包這邊要注意你的環境已經在上面說的ml-agents，而且命令列也在解壓縮完的目錄裡面的ml-agents(有兩層ml-agents\\ml-agents)。確認好之後打\npip install -e .5：安裝Unity3D\n官方指建議Unity 2017.4版以後的版本，這邊建議大家用UnityHub做安裝。\n6：完成建置\n在結束這章節以前請大家先下載好TensorFlowSharp，這個是用來載入預訓練好的模型用的。\n如果本篇文章有幫到你的忙，選單的Donate可以請我喝一杯英式紅茶拿鐵，讓我有更多的咖啡因(X)\n接下來下一個章節：\nUnity ML-Agents 第二章：範本介紹","thumbnail":"https://cdn-images-1.medium.com/max/2544/1*Rl1cSxiTeWM8wMXhQQtrQw.png","plink":"https://chenkuansun.github.io/2019/01/31/Unity_ML_01/"},{"title":"","date":"2020-04-13T23:55:01.646Z","date_formatted":{"ll":"Apr 14, 2020","L":"04/14/2020","MM-DD":"04-14"},"updated":"2020-04-13T23:55:01.646Z","content":"ChenKuan SunI like technology and challenges.\n\nRecent targetComplete 100 Side Project\nCore Competencies\nFrontend EngineerAngular\n\nTypescript\n\nNative Javascript\n\nRxJS \n\nFlux architecture\n\nPostman Runner Testing\nFull Stack\nServerless Architect\n\nAWS, GCP, Azure\n\nCloudflare\nMachine Learning\nPython\n\nTensorflow\n\nROS\n\nWeb Crawling\nDomain Knowledge\nE-commerce\n\nManagement\n　＿\n\n\n\nExperienceSellerlinx Inc. - 11 mos\n Frontend Developer\n\nJan 2019 – Present\n\n\nQoobit Productions Inc. - 1 yrs 3 mos\n Full Stack Developer\n\nFeb 2019 – Present\n\n Software Programmer\n\nSep 2018 – Present\n\n\nRepublic of China Marine Corps - 4 yrs 4 mos\n Secretary officer\n\nNov 2016 – Sep 2018\n\n Platoon Commander\n\nJun 2014 – Nov 2016\n\n\n\nEducationR.O.C. Naval Academy (Electrical Engineering)\n","plink":"https://chenkuansun.github.io/about/"}]